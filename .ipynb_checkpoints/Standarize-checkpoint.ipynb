{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NORMALIZATION\n",
    "###     Gaussian normalization - (x-mean)stddev  ( values between -10,10 )\n",
    "###     Min-max normalization \n",
    "\n",
    "## Encoding Categorical Data\n",
    "   ##     sex(male,female) - +1,-1 instead of binary 0,1\n",
    "   ##     3 values - 1-of-(C-1) encoding 01,10, -1,-1\n",
    "   ##     4 values - 1-of-(C-1) dummy-coding 0001,0010,0100,1000\n",
    "\n",
    "https://visualstudiomagazine.com/articles/2014/01/01/how-to-standardize-data-for-neural-networks.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each row of the matrix x (to have unit length).\n",
    "    \n",
    "    Argument:\n",
    "    x -- A numpy matrix of shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (â‰ˆ 2 lines of code)\n",
    "    # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x,axis=1,keepdims=True)\n",
    "    \n",
    "    # Divide x by its norm.\n",
    "    x = x/x_norm\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizeRows(x) = [[ 0.          0.6         0.8       ]\n",
      " [ 0.13736056  0.82416338  0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"normalizeRows(x) = \" + str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.5       ,  0.33333333],\n",
       "       [ 0.83333333, -0.        ,  0.33333333]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min/Max normalization\n",
    "# Normalized [0,1]\n",
    "b = (x- np.max(x))/-np.ptp(x)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 127,  85],\n",
       "       [212,   0,  85]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized [0,255] as integer\n",
    "c = (255*(x - np.max(x))/-np.ptp(x)).astype(int)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int32 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.,  0.],\n",
       "       [ 1.,  1.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale\n",
    "from sklearn.preprocessing import scale\n",
    "d = scale( x, axis=0, with_mean=True, with_std=True, copy=True )\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 4],\n",
       "       [1, 6, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= (x - np.mean(x)) / np.std(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN preprocessing  Standarizing\n",
    "### http://scikit-learn.org/stable/modules/preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the data to center it by removing the mean value of each feature, \n",
    "# then scale it by dividing non-constant features by their standard deviation\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10.         -100.22703843  130.26755886]\n",
      " [ 120.22703843   10.          -14.05351177]\n",
      " [-100.22703843  120.22703843  -86.21404709]]\n"
     ]
    }
   ],
   "source": [
    "inversed = scaler.inverse_transform(X_scaled)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.        ,  1.        ],\n",
       "       [ 1.        ,  0.5       ,  0.33333333],\n",
       "       [ 0.        ,  1.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize values between 0-1 per column\n",
    "   # notice difference between fit and fit_transform\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_normaized = min_max_scaler.fit_transform(X_train)\n",
    "X_train_normaized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inversed = scaler.inverse_transform(X_train_normaized)\n",
    "#print(inversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good reading for LSTM\n",
    "https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     10.0\n",
      "1     20.0\n",
      "2     30.0\n",
      "3     40.0\n",
      "4     50.0\n",
      "5     60.0\n",
      "6     70.0\n",
      "7     80.0\n",
      "8     90.0\n",
      "9    100.0\n",
      "dtype: float64\n",
      "Min: 10.000000, Max: 100.000000\n",
      "[[ 0.        ]\n",
      " [ 0.11111111]\n",
      " [ 0.22222222]\n",
      " [ 0.33333333]\n",
      " [ 0.44444444]\n",
      " [ 0.55555556]\n",
      " [ 0.66666667]\n",
      " [ 0.77777778]\n",
      " [ 0.88888889]\n",
      " [ 1.        ]]\n",
      "[[  10.]\n",
      " [  20.]\n",
      " [  30.]\n",
      " [  40.]\n",
      " [  50.]\n",
      " [  60.]\n",
      " [  70.]\n",
      " [  80.]\n",
      " [  90.]\n",
      " [ 100.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization 0-1  from Brownlee\n",
    "##############################################\n",
    "\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define contrived series\n",
    "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(values)\n",
    "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
    "# normalize the dataset and print\n",
    "normalized = scaler.transform(values)\n",
    "print(normalized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(normalized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.0\n",
      "1    5.5\n",
      "2    9.0\n",
      "3    2.6\n",
      "4    8.8\n",
      "5    3.0\n",
      "6    4.1\n",
      "7    7.9\n",
      "8    6.3\n",
      "dtype: float64\n",
      "Mean: 5.355556, StandardDeviation: 2.712568\n",
      "[[-1.60569456]\n",
      " [ 0.05325007]\n",
      " [ 1.34354035]\n",
      " [-1.01584758]\n",
      " [ 1.26980948]\n",
      " [-0.86838584]\n",
      " [-0.46286604]\n",
      " [ 0.93802055]\n",
      " [ 0.34817357]]\n",
      "[[ 1. ]\n",
      " [ 5.5]\n",
      " [ 9. ]\n",
      " [ 2.6]\n",
      " [ 8.8]\n",
      " [ 3. ]\n",
      " [ 4.1]\n",
      " [ 7.9]\n",
      " [ 6.3]]\n"
     ]
    }
   ],
   "source": [
    "# Standarize stdev aound zero from Brownlee\n",
    "##############################################\n",
    "\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "\n",
    "# define contrived series\n",
    "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
    "series = Series(data)\n",
    "print(series)\n",
    "# prepare data for normalization\n",
    "values = series.values\n",
    "values = values.reshape((len(values), 1))\n",
    "# train the normalization\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(values)\n",
    "print('Mean: %f, StandardDeviation: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
    "# normalize the dataset and print\n",
    "standardized = scaler.transform(values)\n",
    "print(standardized)\n",
    "# inverse transform and print\n",
    "inversed = scaler.inverse_transform(standardized)\n",
    "print(inversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
