{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from file  DJI\n",
      "Read from file  AAPL\n",
      "Loaded model  AAPL  from disk\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected lstm_3_input to have shape (None, 59, 1) but got array with shape (736, 89, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-d05dc18987e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mjason_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMakePredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'yhat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-d05dc18987e5>\u001b[0m in \u001b[0;36mMakePredictions\u001b[1;34m(dfr)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;31m#print(test_X.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjason_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0myhat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1497\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1498\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    138\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected lstm_3_input to have shape (None, 59, 1) but got array with shape (736, 89, 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data as web\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import os.path\n",
    "import datetime \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy\n",
    "\n",
    "mypath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Quotes\\\\'\n",
    "myModelpath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Models\\\\'\n",
    "settingsPath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Settings\\\\'\n",
    "reportPath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Reports\\\\'\n",
    "\n",
    "# Stochastic Oscilator %K\n",
    "def STOK(close, low, high, n): \n",
    " STOK = ((close - pd.Series.rolling(low, n).min()) / (pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    " return STOK\n",
    "\n",
    "# Stochastic Oscilator %D\n",
    "def STOD(close, low, high, n):\n",
    "    STOK = ((close - pd.Series.rolling(low, n).min()) / (pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    "    STOD = pd.Series.rolling(STOK, 3).mean()\n",
    "    return STOD\n",
    "    #STOD\n",
    "\n",
    "    \n",
    "def RSI(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "   # rs = pd.stats.moments.ewma(u, com=period-1, adjust=False) / \\\n",
    "   #      pd.stats.moments.ewma(d, com=period-1, adjust=False)\n",
    "    rs= pd.Series.ewm(u,com=period-1, min_periods=0,adjust=False,ignore_na=False).mean() / \\\n",
    "        pd.Series.ewm(d,com=period-1,min_periods=0,adjust=False,ignore_na=False).mean()\n",
    "    return 100 - 100 / (1 + rs)    \n",
    "\n",
    "\n",
    "def getData(item):\n",
    "    start = datetime.datetime(2016, 12, 21)\n",
    "    end = datetime.datetime.now()\n",
    "    #print( start,end) \n",
    "    file_path=mypath+item +'.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"No data\")\n",
    "    else:\n",
    "        print(\"Read from file \", item)  \n",
    "        try:     \n",
    "            df = read_csv(file_path)\n",
    "            df['Date']=pd.to_datetime(df['Date']) #important for sorting\n",
    "            df.set_index(\"Date\",inplace=True)\n",
    "        except: print(\"Exception caught\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def cleanData( df):\n",
    "    # drop Close and Volume, keep Adj Close\n",
    "    \n",
    "    df1 = df.drop('Close', 1)\n",
    "    df1 = df1.drop('Volume', 1)\n",
    "    if 'y' in df1.columns:\n",
    "        df1 = df1.drop('y', 1)\n",
    "    if 'yhat' in df1.columns:\n",
    "        df1 = df1.drop('yhat', 1)\n",
    "    if 'yhathat' in df1.columns:\n",
    "        df1 = df1.drop('yhathat', 1)\n",
    "    df1.rename(columns={'Adj Close': 'Close', 'oldName2': 'newName2'}, inplace=True)\n",
    "    return df1\n",
    "\n",
    "\n",
    "def engFeatures(df):\n",
    "    df['%K'] = STOK(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['%D'] = STOD(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['Avg5'] =pd.Series.rolling(df['Close'],5).mean()\n",
    "    df['Avg10'] =pd.Series.rolling(df['Close'],10).mean()\n",
    "    df['RSI14'] = RSI(df['Close'],14)\n",
    "    df['RSI7'] = RSI(df['Close'],7)\n",
    "    #df['Date']=pd.to_datetime(df['Date'])\n",
    "    df.sort_index(ascending=False,inplace=True)\n",
    "    df['Rise'] = (  pd.Series.rolling(df['Close'],5).max()-df['Close'] >df['Close']*0.04)*1\n",
    "    df.sort_index(ascending=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def rescale( df):\n",
    "    df.dropna(inplace=True)\n",
    "    values = df.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float')\n",
    "    #drop columns to simplify test\n",
    "    timesteps=3\n",
    "    features = values.shape[1]-1\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    #scaled = scaler.fit_transform(values)\n",
    "    scaled = values #scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled,timesteps, 1)\n",
    "    # drop columns we don't want to predict\n",
    "    #reframed.drop(reframed.columns[[10,11,12,13,14,15,16,17,18,19,20]], axis=1, inplace=True)\n",
    "    reframed= pd.DataFrame(reframed)\n",
    "    return reframed\n",
    "#print(reframed.head())\n",
    "#reframed.iloc[0]\n",
    "\n",
    "#def cleadData( df1,df2):\n",
    "    \n",
    "#    return cleanSet\n",
    "#####################################################################3\n",
    "def loadModel( item ):\n",
    "    # later...\n",
    "    # load json and create model\n",
    "    from keras.models import model_from_json\n",
    "\n",
    "    json_file = open(myModelpath + item+'_model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(myModelpath + item +'_model.h5')\n",
    "    print(\"Loaded model \", item,\" from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    #loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) #61.29\n",
    "    loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #score = loaded_model.evaluate( test_X, test_y, verbose=0)\n",
    "    #print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "    return loaded_model\n",
    "\n",
    "#######################################################################\n",
    "def MakePredictions( dfr):\n",
    "    \n",
    "    dframeclean=cleanData(dfr)\n",
    "    #djiframe=getData('DJI')  # this can be loaded once\n",
    "    #djiframe=cleanData(djiframe)\n",
    "    #dframe=dframe.join(djiframe, lsuffix='_left', rsuffix='_right')\n",
    "    dframeclean=dframeclean.join(djiframe , rsuffix='_right')\n",
    "    fullFrame=engFeatures(dframeclean)\n",
    "    reframed=rescale(fullFrame)\n",
    "    \n",
    "    #test on entire dataframe\n",
    "    test = reframed.values\n",
    "    test_X, test_y = test[:, :-1], to_categorical(test[:, -1])\n",
    "    test_X = numpy.reshape(test_X, (test_X.shape[0], test_X.shape[1],1))\n",
    "    #print(test_X.shape)\n",
    "    yhat = jason_model.predict(test_X)\n",
    "    from numpy import argmax\n",
    "    yhat=argmax(yhat,axis=1)\n",
    "    #print(test_X.shape, test_y.shape,yhat.shape, dframe.shape)\n",
    "   \n",
    "    # reframing makes original dframe shorter\n",
    "    # below code makes them all equal length by padding with zeros\n",
    "\n",
    "    yhat=yhat.reshape(yhat.shape[0],1)\n",
    "    #print(dfr.shape,yhat.shape)\n",
    "    nz=pd.DataFrame(np.zeros(dfr.shape[0]-yhat.shape[0]))\n",
    "    yhat1=nz.append(pd.DataFrame(yhat) )\n",
    "    y=nz.append( pd.DataFrame(argmax(test_y,1) ))\n",
    "    #print( yhat1.shape, y.shape )\n",
    "    \n",
    "    #put results back into dframe\n",
    "    dfr['y']=y.values\n",
    "    dfr['yhat']=yhat1.values\n",
    "    dfr['yhathat']=np.zeros(yhat1.shape[0]) # prepare empty column\n",
    "    print(\"Finished MakePredictions\" )\n",
    "    return dfr\n",
    "#############################################################################\n",
    "#############################################################################\n",
    "## MAIN EXECUTION \n",
    "file = open(reportPath + 'Report.txt','w+') \n",
    "df1 = read_csv(settingsPath + 'List1.csv', header=None)\n",
    "df2 = read_csv(settingsPath + 'List2.csv', header=None)\n",
    "df3 = read_csv(settingsPath + 'List3.csv', header=None)\n",
    "df=pd.concat([df1,df2,df3])\n",
    "djiframe=getData('DJI')  # this can be loaded once\n",
    "djiframe=cleanData(djiframe)\n",
    "\n",
    "file.write(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +  \" Verified \" +str(len(df.index)) + \"models \\n\") \n",
    "\n",
    "for index in range (df.shape[0]):\n",
    "    itemname=df.iloc[index,0]\n",
    "    #print ('Current item :', itemname)\n",
    "    #itemname = 'BA'\n",
    "    dframe = getData(itemname)\n",
    "    jason_model = loadModel(itemname)\n",
    "\n",
    "    df1 = MakePredictions(dframe)\n",
    "    df2=df1[-2:]\n",
    "    if (df2['yhat'].any() > 0):\n",
    "        print('----------got it',itemname)\n",
    "        file.write(\"got it \" + itemname +\"\\n\") \n",
    "\n",
    "file.write(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\") \n",
    "file.close() \n",
    "\n",
    "#PrintReport(df1)\n",
    "#df1.tail\n",
    "\n",
    "## get all predicted values yhat and verify they are still valid when \n",
    "## at the end of the dataset. Cut dataframe in pieces and predict yhathat\n",
    "#predictedlist=df1.index[df1['yhat'] >0]\n",
    "#predictedlist[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "can't do nonzero end-relative seeks",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-dac376fea276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmypath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"AAPL.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSEEK_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnsupportedOperation\u001b[0m: can't do nonzero end-relative seeks"
     ]
    }
   ],
   "source": [
    "filename=mypath+\"AAPL.csv\"\n",
    "fo = open(filename, \"r\")\n",
    "fo.seek(-80, os.SEEK_END)\n",
    "line = fo.readlines()[-1]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-7ae2a205acb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmypath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"AAPL.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgetLastLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-77-7ae2a205acb6>\u001b[0m in \u001b[0;36mgetLastLine\u001b[1;34m(fname, maxLineLength)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetLastLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxLineLength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0mfp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmaxLineLength\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 2 means \"from the end of the file\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not callable"
     ]
    }
   ],
   "source": [
    "def getLastLine(fname, maxLineLength=80):\n",
    "  fp=file(fname, \"rb\")\n",
    "  fp.seek(-maxLineLength-1, 2) # 2 means \"from the end of the file\"\n",
    "  return fp.readlines()[-1]\n",
    "\n",
    "filename=mypath+\"AAPL.csv\"\n",
    "getLastLine(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
