{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from file\n",
      "Updating\n",
      "2017-12-01 00:00:00 2017-11-06 00:00:00\n",
      "Read from file\n",
      "Updating\n"
     ]
    },
    {
     "ename": "RemoteDataError",
     "evalue": "Unable to read URL: https://query1.finance.yahoo.com/v7/finance/download/DJI?period1=1512190800&period2=1512363599&interval=1d&events=history&crumb=V5qxV%5Cu002F0VyU%5Cu002F",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-34a5e88d431b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[0mdframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[0mdframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcleanData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m \u001b[0mdjiframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DJI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[0mdjiframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcleanData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdjiframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;31m#dframe=dframe.join(djiframe, lsuffix='_left', rsuffix='_right')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-34a5e88d431b>\u001b[0m in \u001b[0;36mgetData\u001b[1;34m(item)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0md2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlastDate\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m#print(d2,end )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mweb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'yahoo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mupdateDate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdateDate\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\data.py\u001b[0m in \u001b[0;36mDataReader\u001b[1;34m(name, data_source, start, end, retry_count, pause, session, access_key)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                 \u001b[0madjust_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                                 \u001b[0mretry_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                                 session=session).read()\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yahoo-actions\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\yahoo\\daily.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;34m\"\"\" read one data from specified URL \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYahooDailyReader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ret_Index'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calc_return_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Adj Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             df = self._read_one_data(self.url,\n\u001b[1;32m--> 181\u001b[1;33m                                      params=self._get_params(self.symbols))\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;31m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;34m\"\"\" read one data from specified URL \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'string'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_url_as_StringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'json'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_read_url_as_StringIO\u001b[1;34m(self, url, params)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mOpen\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mand\u001b[0m \u001b[0mretry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mwnuk\\Anaconda3\\lib\\site-packages\\pandas_datareader\\base.py\u001b[0m in \u001b[0;36m_get_response\u001b[1;34m(self, url, params, headers)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"?\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unable to read URL: {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRemoteDataError\u001b[0m: Unable to read URL: https://query1.finance.yahoo.com/v7/finance/download/DJI?period1=1512190800&period2=1512363599&interval=1d&events=history&crumb=V5qxV%5Cu002F0VyU%5Cu002F"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_datareader import data as web\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import os.path\n",
    "import datetime \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy\n",
    "\n",
    "\n",
    "# Stochastic Oscilator %K\n",
    "def STOK(close, low, high, n): \n",
    " STOK = ((close - pd.Series.rolling(low, n).min()) / (pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    " return STOK\n",
    "\n",
    "# Stochastic Oscilator %D\n",
    "def STOD(close, low, high, n):\n",
    "    STOK = ((close - pd.Series.rolling(low, n).min()) / (pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    "    STOD = pd.Series.rolling(STOK, 3).mean()\n",
    "    return STOD\n",
    "    #STOD\n",
    "\n",
    "    \n",
    "def RSI(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "   # rs = pd.stats.moments.ewma(u, com=period-1, adjust=False) / \\\n",
    "   #      pd.stats.moments.ewma(d, com=period-1, adjust=False)\n",
    "    rs= pd.Series.ewm(u,com=period-1, min_periods=0,adjust=False,ignore_na=False).mean() / \\\n",
    "        pd.Series.ewm(d,com=period-1,min_periods=0,adjust=False,ignore_na=False).mean()\n",
    "    return 100 - 100 / (1 + rs)    \n",
    "\n",
    "\n",
    "def getData(item):\n",
    "    start = datetime.datetime(2016, 12, 21)\n",
    "    end = datetime.datetime.now()\n",
    "    #print( start,end) \n",
    "    file_path='./data/'+item +'.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Empty set\")\n",
    "        df =web.DataReader(item,'yahoo',start,end)  \n",
    "        df=df.round(2)\n",
    "        \n",
    "        df.to_csv('./data/' + item + '.csv')\n",
    "        #df['Date']=pd.to_datetime(df['Date']) #important for sorting\n",
    "        #df.set_index(\"Date\",inplace=True)\n",
    "        df.index.name = 'Date'\n",
    "    else:\n",
    "        print(\"Read from file\")  \n",
    "        df = read_csv(file_path)\n",
    "        df['Date']=pd.to_datetime(df['Date']) #important for sorting\n",
    "        df.set_index(\"Date\",inplace=True)\n",
    "\n",
    "        #end = datetime.datetime.now()\n",
    "        lastDate=df.index[df.shape[0]-1] #last recorded day\n",
    "        d1 = lastDate #datetime.datetime.strptime(lastDate, \"%Y-%m-%d\")  \n",
    "        #d1 = datetime.datetime.strptime(lastDate)\n",
    "        #print(d1,end )\n",
    "        if( d1 < end - datetime.timedelta(days=2)): # dont update on Sat or Sun\n",
    "            print(\"Updating\")  \n",
    "            d2 = lastDate + datetime.timedelta(days=1)\n",
    "            #print(d2,end )\n",
    "            df1 =web.DataReader(item,'yahoo',d2,end)  \n",
    "            updateDate=df1.index[df1.shape[0]-1]\n",
    "            print(updateDate , d1)\n",
    "            if (updateDate !=  d1): #yahoo gives unwanted records\n",
    "                df1=df1.round(2)\n",
    "                df=pd.concat([df,df1])\n",
    "                df.index= pd.to_datetime(df.index, format=\"%Y-%m-%d\") # drop time \n",
    "                df.to_csv('./data/' + item + '.csv')\n",
    "            else:\n",
    "                print(\"No need to update\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def cleanData( df):\n",
    "    # drop Close and Volume, keep Adj Close\n",
    "    df1 = df.drop('Close', 1)\n",
    "    df1 = df1.drop('Volume', 1)\n",
    "    df1.rename(columns={'Adj Close': 'Close', 'oldName2': 'newName2'}, inplace=True)\n",
    "    return df1\n",
    "\n",
    "\n",
    "def engFeatures(df):\n",
    "    df['%K'] = STOK(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['%D'] = STOD(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['Avg5'] =pd.Series.rolling(df['Close'],5).mean()\n",
    "    df['Avg10'] =pd.Series.rolling(df['Close'],10).mean()\n",
    "    df['RSI14'] = RSI(df['Close'],14)\n",
    "    df['RSI7'] = RSI(df['Close'],7)\n",
    "    #df['Date']=pd.to_datetime(df['Date'])\n",
    "    df.sort_index(ascending=False,inplace=True)\n",
    "    df['Rise'] = (  pd.Series.rolling(df['Close'],5).max()-df['Close'] >df['Close']*0.04)*1\n",
    "    df.sort_index(ascending=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def rescale( df):\n",
    "    df.dropna(inplace=True)\n",
    "    values = df.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float')\n",
    "    #drop columns to simplify test\n",
    "    timesteps=3\n",
    "    features = values.shape[1]-1\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    #scaled = scaler.fit_transform(values)\n",
    "    scaled = values #scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled,timesteps, 1)\n",
    "    # drop columns we don't want to predict\n",
    "    #reframed.drop(reframed.columns[[10,11,12,13,14,15,16,17,18,19,20]], axis=1, inplace=True)\n",
    "    reframed= pd.DataFrame(reframed)\n",
    "    return reframed\n",
    "#print(reframed.head())\n",
    "#reframed.iloc[0]\n",
    "\n",
    "def cleadData( df1,df2):\n",
    "    \n",
    "    return cleanSet\n",
    "#####################################################################3\n",
    "\n",
    "itemname='GM'\n",
    "dframe=getData(itemname)\n",
    "dframe=cleanData(dframe)\n",
    "djiframe=getData('DJI')\n",
    "djiframe=cleanData(djiframe)\n",
    "#dframe=dframe.join(djiframe, lsuffix='_left', rsuffix='_right')\n",
    "dframe=dframe.join(djiframe , rsuffix='_right')\n",
    "fullFrame=engFeatures(dframe)\n",
    "reframed=rescale(fullFrame)\n",
    "\n",
    "\n",
    "values = reframed.values\n",
    "n_test_size = 50\n",
    "\n",
    "test = values[values.shape[0]- n_test_size:, :]\n",
    "# split into input and outputs\n",
    "#train_X, train_y = train[:, :-1], to_categorical(train[:, -1])\n",
    "#train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], to_categorical(test[:, -1])\n",
    "#test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "#train_X = numpy.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1 ))\n",
    "\n",
    "test_X = numpy.reshape(test_X, (test_X.shape[0], test_X.shape[1],1))\n",
    "\n",
    "print(test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "\n",
    "# later...\n",
    "# load json and create model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('./data/' + itemname +'_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights('./data/' + itemname +'_model.h5')\n",
    "print(\"Loaded model from disk\")\n",
    "# evaluate loaded model on test data\n",
    "#loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) #61.29\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate( test_X, test_y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "yhat = loaded_model.predict(test_X)\n",
    "from numpy import argmax\n",
    "yhat=argmax(yhat,axis=1)\n",
    "yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fullFrame.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(test_y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Rise</th>\n",
       "      <th>window</th>\n",
       "      <th>Rise1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-20</th>\n",
       "      <td>45.61</td>\n",
       "      <td>0</td>\n",
       "      <td>46.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>45.15</td>\n",
       "      <td>0</td>\n",
       "      <td>46.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>46.48</td>\n",
       "      <td>0</td>\n",
       "      <td>46.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>45.12</td>\n",
       "      <td>0</td>\n",
       "      <td>45.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>45.25</td>\n",
       "      <td>0</td>\n",
       "      <td>45.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>44.64</td>\n",
       "      <td>0</td>\n",
       "      <td>44.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>43.37</td>\n",
       "      <td>0</td>\n",
       "      <td>43.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>42.98</td>\n",
       "      <td>0</td>\n",
       "      <td>43.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>43.13</td>\n",
       "      <td>0</td>\n",
       "      <td>43.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>42.60</td>\n",
       "      <td>0</td>\n",
       "      <td>42.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>42.34</td>\n",
       "      <td>0</td>\n",
       "      <td>42.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>42.14</td>\n",
       "      <td>0</td>\n",
       "      <td>42.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07</th>\n",
       "      <td>41.70</td>\n",
       "      <td>1</td>\n",
       "      <td>43.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>42.11</td>\n",
       "      <td>0</td>\n",
       "      <td>43.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>42.11</td>\n",
       "      <td>0</td>\n",
       "      <td>43.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>42.66</td>\n",
       "      <td>0</td>\n",
       "      <td>43.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>43.57</td>\n",
       "      <td>0</td>\n",
       "      <td>43.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14</th>\n",
       "      <td>43.00</td>\n",
       "      <td>1</td>\n",
       "      <td>44.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15</th>\n",
       "      <td>42.86</td>\n",
       "      <td>1</td>\n",
       "      <td>44.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>43.60</td>\n",
       "      <td>0</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>43.88</td>\n",
       "      <td>0</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>44.88</td>\n",
       "      <td>0</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>44.97</td>\n",
       "      <td>0</td>\n",
       "      <td>44.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>44.29</td>\n",
       "      <td>0</td>\n",
       "      <td>44.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-24</th>\n",
       "      <td>44.46</td>\n",
       "      <td>0</td>\n",
       "      <td>44.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-27</th>\n",
       "      <td>44.17</td>\n",
       "      <td>0</td>\n",
       "      <td>44.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-28</th>\n",
       "      <td>44.92</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29</th>\n",
       "      <td>43.81</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30</th>\n",
       "      <td>43.09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>42.79</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close  Rise  window  Rise1\n",
       "Date                                  \n",
       "2017-10-20  45.61     0   46.48      0\n",
       "2017-10-23  45.15     0   46.48      0\n",
       "2017-10-24  46.48     0   46.48      0\n",
       "2017-10-25  45.12     0   45.25      0\n",
       "2017-10-26  45.25     0   45.25      0\n",
       "2017-10-27  44.64     0   44.64      0\n",
       "2017-10-30  43.37     0   43.37      0\n",
       "2017-10-31  42.98     0   43.13      0\n",
       "2017-11-01  43.13     0   43.13      0\n",
       "2017-11-02  42.60     0   42.60      0\n",
       "2017-11-03  42.34     0   42.34      0\n",
       "2017-11-06  42.14     0   42.66      0\n",
       "2017-11-07  41.70     1   43.57      1\n",
       "2017-11-08  42.11     0   43.57      0\n",
       "2017-11-09  42.11     0   43.57      0\n",
       "2017-11-10  42.66     0   43.60      0\n",
       "2017-11-13  43.57     0   43.88      0\n",
       "2017-11-14  43.00     1   44.88      1\n",
       "2017-11-15  42.86     1   44.97      1\n",
       "2017-11-16  43.60     0   44.97      0\n",
       "2017-11-17  43.88     0   44.97      0\n",
       "2017-11-20  44.88     0   44.97      0\n",
       "2017-11-21  44.97     0   44.97      0\n",
       "2017-11-22  44.29     0   44.92      0\n",
       "2017-11-24  44.46     0   44.92      0\n",
       "2017-11-27  44.17     0   44.92      0\n",
       "2017-11-28  44.92     0     NaN      0\n",
       "2017-11-29  43.81     0     NaN      0\n",
       "2017-11-30  43.09     0     NaN      0\n",
       "2017-12-01  42.79     0     NaN      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fullFrame['Date']=pd.to_datetime(fullFrame['Date'])\n",
    "df1=fullFrame[['Close','Rise']].iloc[-30:] \n",
    "\n",
    "df1=df1.sort_index(ascending=False)\n",
    "df1['window']=pd.Series.rolling(df1['Close'],5).max()\n",
    "df1['Rise1'] = (  pd.Series.rolling(df1['Close'],5).max()-df1['Close'] >df1['Close']*0.04)*1\n",
    "#df['yhat'] =yhat\n",
    "df1=df1.sort_index(ascending=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-11</th>\n",
       "      <td>45.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-12</th>\n",
       "      <td>44.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-13</th>\n",
       "      <td>45.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-16</th>\n",
       "      <td>45.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-17</th>\n",
       "      <td>45.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-18</th>\n",
       "      <td>45.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-19</th>\n",
       "      <td>45.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-20</th>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>45.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-24</th>\n",
       "      <td>46.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-25</th>\n",
       "      <td>45.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-26</th>\n",
       "      <td>45.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-27</th>\n",
       "      <td>44.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>43.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-31</th>\n",
       "      <td>42.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>43.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-02</th>\n",
       "      <td>42.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-03</th>\n",
       "      <td>42.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-06</th>\n",
       "      <td>42.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-07</th>\n",
       "      <td>41.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-10</th>\n",
       "      <td>42.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>43.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14</th>\n",
       "      <td>43.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15</th>\n",
       "      <td>42.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>43.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>43.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>44.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>44.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close\n",
       "Date             \n",
       "2017-10-11  45.47\n",
       "2017-10-12  44.89\n",
       "2017-10-13  45.88\n",
       "2017-10-16  45.76\n",
       "2017-10-17  45.02\n",
       "2017-10-18  45.12\n",
       "2017-10-19  45.35\n",
       "2017-10-20  45.61\n",
       "2017-10-23  45.15\n",
       "2017-10-24  46.48\n",
       "2017-10-25  45.12\n",
       "2017-10-26  45.25\n",
       "2017-10-27  44.64\n",
       "2017-10-30  43.37\n",
       "2017-10-31  42.98\n",
       "2017-11-01  43.13\n",
       "2017-11-02  42.60\n",
       "2017-11-03  42.34\n",
       "2017-11-06  42.14\n",
       "2017-11-07  41.70\n",
       "2017-11-08  42.11\n",
       "2017-11-09  42.11\n",
       "2017-11-10  42.66\n",
       "2017-11-13  43.57\n",
       "2017-11-14  43.00\n",
       "2017-11-15  42.86\n",
       "2017-11-16  43.60\n",
       "2017-11-17  43.88\n",
       "2017-11-20  44.88\n",
       "2017-11-21  44.97"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullFrame[['Close']].iloc[-30:] \n",
    "#dframe[['Close']].iloc[-30:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 38.54      ,  38.87      ,  38.54      , ...,  60.7658393 ,\n",
       "         66.16377762,   1.        ],\n",
       "       [ 34.88      ,  35.14      ,  34.62      , ...,  53.23391581,\n",
       "         56.53293806,   1.        ],\n",
       "       [ 29.01      ,  29.22      ,  28.62      , ...,  72.76774699,\n",
       "         76.73209434,   0.        ],\n",
       "       ..., \n",
       "       [ 29.5       ,  29.94      ,  29.5       , ...,  30.80723241,\n",
       "         19.73558947,   0.        ],\n",
       "       [ 31.85      ,  32.        ,  31.68      , ...,  46.98693043,\n",
       "         53.31674551,   0.        ],\n",
       "       [ 36.8       ,  37.04      ,  36.62      , ...,  36.79397471,\n",
       "         22.05245118,   0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open         float64\n",
      "High         float64\n",
      "Low          float64\n",
      "Close        float64\n",
      "Adj Close    float64\n",
      "Volume         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2017-11-20T00:00:00.000000000', '2017-11-21T00:00:00.000000000',\n",
       "       '2017-11-22T00:00:00.000000000', '2017-11-24T00:00:00.000000000',\n",
       "       '2017-11-27T00:00:00.000000000', '2017-11-28T00:00:00.000000000',\n",
       "       '2017-11-29T00:00:00.000000000', '2017-11-30T00:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    item='F'\n",
    "    start = datetime.datetime(2017, 11, 20)\n",
    "    end = datetime.datetime.now()\n",
    "    #print( start,end) \n",
    "    file_path='./data/'+item +'.csv'\n",
    "    df =web.DataReader(item,'yahoo',start,end)  \n",
    "    print(df.dtypes)\n",
    "    df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
