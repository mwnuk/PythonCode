{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current item : UTX\n",
      "Read from file\n",
      "Read from file\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_41 (LSTM)               (None, 89, 20)            1760      \n",
      "_________________________________________________________________\n",
      "lstm_42 (LSTM)               (None, 20)                3280      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 8)                 168       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 5,226\n",
      "Trainable params: 5,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "128s - loss: 0.1707 - acc: 0.9674\n",
      "Epoch 2/100\n",
      "119s - loss: 0.1445 - acc: 0.9674\n",
      "Epoch 3/100\n",
      "126s - loss: 0.1394 - acc: 0.9674\n",
      "Epoch 4/100\n",
      "124s - loss: 0.1422 - acc: 0.9674\n",
      "Epoch 5/100\n",
      "124s - loss: 0.1391 - acc: 0.9674\n",
      "Epoch 6/100\n",
      "124s - loss: 0.1374 - acc: 0.9674\n",
      "Epoch 7/100\n",
      "125s - loss: 0.1323 - acc: 0.9674\n",
      "Epoch 8/100\n",
      "121s - loss: 0.1291 - acc: 0.9674\n",
      "Epoch 9/100\n",
      "116s - loss: 0.1309 - acc: 0.9674\n",
      "Epoch 10/100\n",
      "118s - loss: 0.1303 - acc: 0.9674\n",
      "Epoch 11/100\n",
      "117s - loss: 0.1311 - acc: 0.9674\n",
      "Epoch 12/100\n",
      "117s - loss: 0.1292 - acc: 0.9674\n",
      "Epoch 13/100\n",
      "117s - loss: 0.1312 - acc: 0.9674\n",
      "Epoch 14/100\n",
      "118s - loss: 0.1289 - acc: 0.9674\n",
      "Epoch 15/100\n",
      "120s - loss: 0.1259 - acc: 0.9674\n",
      "Epoch 16/100\n",
      "125s - loss: 0.1283 - acc: 0.9674\n",
      "Epoch 17/100\n",
      "122s - loss: 0.1275 - acc: 0.9674\n",
      "Epoch 18/100\n",
      "117s - loss: 0.1257 - acc: 0.9674\n",
      "Epoch 19/100\n",
      "117s - loss: 0.1215 - acc: 0.9674\n",
      "Epoch 20/100\n",
      "118s - loss: 0.1236 - acc: 0.9674\n",
      "Epoch 21/100\n",
      "120s - loss: 0.1193 - acc: 0.9674\n",
      "Epoch 22/100\n",
      "116s - loss: 0.1178 - acc: 0.9674\n",
      "Epoch 23/100\n",
      "117s - loss: 0.1172 - acc: 0.9674\n",
      "Epoch 24/100\n",
      "117s - loss: 0.1110 - acc: 0.9674\n",
      "Epoch 25/100\n",
      "117s - loss: 0.1038 - acc: 0.9674\n",
      "Epoch 26/100\n",
      "120s - loss: 0.1046 - acc: 0.9674\n",
      "Epoch 27/100\n",
      "123s - loss: 0.1092 - acc: 0.9674\n",
      "Epoch 28/100\n",
      "125s - loss: 0.1182 - acc: 0.9674\n",
      "Epoch 29/100\n",
      "124s - loss: 0.1121 - acc: 0.9728\n",
      "Epoch 30/100\n",
      "119s - loss: 0.1182 - acc: 0.9701\n",
      "Epoch 31/100\n",
      "116s - loss: 0.1017 - acc: 0.9769\n",
      "Epoch 32/100\n",
      "118s - loss: 0.1094 - acc: 0.9755\n",
      "Epoch 33/100\n",
      "120s - loss: 0.1089 - acc: 0.9715\n",
      "Epoch 34/100\n",
      "119s - loss: 0.0997 - acc: 0.9769\n",
      "Epoch 35/100\n",
      "119s - loss: 0.0955 - acc: 0.9783\n",
      "Epoch 36/100\n",
      "116s - loss: 0.1005 - acc: 0.9769\n",
      "Epoch 37/100\n",
      "117s - loss: 0.1056 - acc: 0.9715\n",
      "Epoch 38/100\n",
      "120s - loss: 0.0954 - acc: 0.9783\n",
      "Epoch 39/100\n",
      "117s - loss: 0.0884 - acc: 0.9823\n",
      "Epoch 40/100\n",
      "117s - loss: 0.1152 - acc: 0.9742\n",
      "Epoch 41/100\n",
      "120s - loss: 0.0942 - acc: 0.9769\n",
      "Epoch 42/100\n",
      "119s - loss: 0.0956 - acc: 0.9755\n",
      "Epoch 43/100\n",
      "118s - loss: 0.0931 - acc: 0.9783\n",
      "Epoch 44/100\n",
      "121s - loss: 0.0900 - acc: 0.9810\n",
      "Epoch 45/100\n",
      "122s - loss: 0.0873 - acc: 0.9823\n",
      "Epoch 46/100\n",
      "124s - loss: 0.0961 - acc: 0.9796\n",
      "Epoch 47/100\n",
      "122s - loss: 0.0930 - acc: 0.9783\n",
      "Epoch 48/100\n",
      "121s - loss: 0.0893 - acc: 0.9783\n",
      "Epoch 49/100\n",
      "122s - loss: 0.0934 - acc: 0.9783\n",
      "Epoch 50/100\n",
      "121s - loss: 0.0866 - acc: 0.9810\n",
      "Epoch 51/100\n",
      "121s - loss: 0.0892 - acc: 0.9796\n",
      "Epoch 52/100\n",
      "121s - loss: 0.0847 - acc: 0.9823\n",
      "Epoch 53/100\n",
      "121s - loss: 0.0813 - acc: 0.9796\n",
      "Epoch 54/100\n",
      "121s - loss: 0.0848 - acc: 0.9823\n",
      "Epoch 55/100\n",
      "124s - loss: 0.0787 - acc: 0.9810\n",
      "Epoch 56/100\n",
      "123s - loss: 0.0985 - acc: 0.9769\n",
      "Epoch 57/100\n",
      "119s - loss: 0.0881 - acc: 0.9783\n",
      "Epoch 58/100\n",
      "119s - loss: 0.0808 - acc: 0.9823\n",
      "Epoch 59/100\n",
      "121s - loss: 0.0827 - acc: 0.9823\n",
      "Epoch 60/100\n",
      "122s - loss: 0.0788 - acc: 0.9823\n",
      "Epoch 61/100\n",
      "122s - loss: 0.0849 - acc: 0.9796\n",
      "Epoch 62/100\n",
      "124s - loss: 0.0758 - acc: 0.9810\n",
      "Epoch 63/100\n",
      "122s - loss: 0.0847 - acc: 0.9783\n",
      "Epoch 64/100\n",
      "122s - loss: 0.0807 - acc: 0.9810\n",
      "Epoch 65/100\n",
      "123s - loss: 0.0797 - acc: 0.9810\n",
      "Epoch 66/100\n",
      "121s - loss: 0.0788 - acc: 0.9837\n",
      "Epoch 67/100\n",
      "122s - loss: 0.0769 - acc: 0.9796\n",
      "Epoch 68/100\n",
      "125s - loss: 0.0748 - acc: 0.9823\n",
      "Epoch 69/100\n",
      "123s - loss: 0.0738 - acc: 0.9837\n",
      "Epoch 70/100\n",
      "120s - loss: 0.0767 - acc: 0.9783\n",
      "Epoch 71/100\n",
      "119s - loss: 0.0695 - acc: 0.9837\n",
      "Epoch 72/100\n",
      "121s - loss: 0.0732 - acc: 0.9810\n",
      "Epoch 73/100\n",
      "121s - loss: 0.0629 - acc: 0.9851\n",
      "Epoch 74/100\n",
      "126s - loss: 0.0820 - acc: 0.9810\n",
      "Epoch 75/100\n",
      "121s - loss: 0.0797 - acc: 0.9769\n",
      "Epoch 76/100\n",
      "120s - loss: 0.0668 - acc: 0.9810\n",
      "Epoch 77/100\n",
      "121s - loss: 0.0685 - acc: 0.9810\n",
      "Epoch 78/100\n",
      "120s - loss: 0.0661 - acc: 0.9837\n",
      "Epoch 79/100\n",
      "120s - loss: 0.0581 - acc: 0.9837\n",
      "Epoch 80/100\n",
      "122s - loss: 0.0529 - acc: 0.9864\n",
      "Epoch 81/100\n",
      "120s - loss: 0.0668 - acc: 0.9823\n",
      "Epoch 82/100\n",
      "120s - loss: 0.0841 - acc: 0.9783\n",
      "Epoch 83/100\n",
      "118s - loss: 0.0617 - acc: 0.9837\n",
      "Epoch 84/100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from pandas_datareader import data as web\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import os.path\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numba import autojit\n",
    "\n",
    "#mypath=''./data/''\n",
    "mypath=\"C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Quotes\\\\\"\n",
    "myModelpath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Models\\\\'\n",
    "settingsPath='C:\\\\Users\\\\mwnuk\\\\Dropbox\\\\Settings\\\\'\n",
    "\n",
    "#####################################################################\n",
    "# Stochastic Oscilator %K\n",
    "def STOK(close, low, high, n):\n",
    "    STOK = ((close - pd.Series.rolling(low, n).min()) / (\n",
    "    pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    "    return STOK\n",
    "\n",
    "\n",
    "# Stochastic Oscilator %D\n",
    "def STOD(close, low, high, n):\n",
    "    STOK = ((close - pd.Series.rolling(low, n).min()) / (\n",
    "    pd.Series.rolling(high, n).max() - pd.Series.rolling(low, n).min())) * 100\n",
    "    STOD = pd.Series.rolling(STOK, 3).mean()\n",
    "    return STOD\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "def RSI(series, period):\n",
    "    delta = series.diff().dropna()\n",
    "    u = delta * 0\n",
    "    d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]\n",
    "    d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period - 1]] = np.mean(u[:period])  # first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period - 1)])\n",
    "    d[d.index[period - 1]] = np.mean(d[:period])  # first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period - 1)])\n",
    "    # rs = pd.stats.moments.ewma(u, com=period-1, adjust=False) / \\\n",
    "    #      pd.stats.moments.ewma(d, com=period-1, adjust=False)\n",
    "    rs = pd.Series.ewm(u, com=period - 1, min_periods=0, adjust=False, ignore_na=False).mean() / \\\n",
    "         pd.Series.ewm(d, com=period - 1, min_periods=0, adjust=False, ignore_na=False).mean()\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def getData(item):\n",
    "    start = datetime.datetime(2015, 12, 21)\n",
    "    end = datetime.datetime.now()\n",
    "    # print( start,end)\n",
    "    file_path = mypath + item + '.csv'\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Empty set\")\n",
    "        df = web.DataReader(item, 'yahoo', start, end)\n",
    "        df = df.round(2)\n",
    "\n",
    "        df.to_csv(mypath + item + '.csv')\n",
    "        # df['Date']=pd.to_datetime(df['Date']) #important for sorting\n",
    "        # df.set_index(\"Date\",inplace=True)\n",
    "        df.index.name = 'Date'\n",
    "    else:\n",
    "        print(\"Read from file\")\n",
    "        df = read_csv(file_path)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])  # important for sorting\n",
    "        df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def cleanData(df):\n",
    "    # drop Close and Volume, keep Adj Close\n",
    "    df1 = df.drop('Close', 1)\n",
    "    df1 = df1.drop('Volume', 1)\n",
    "    df1.rename(columns={'Adj Close': 'Close', 'oldName2': 'newName2'}, inplace=True)\n",
    "    return df1\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Engineer features\n",
    "def engFeatures(df):\n",
    "    df['%K'] = STOK(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['%D'] = STOD(df['Close'], df['Low'], df['High'], 14)\n",
    "    df['Avg5'] = pd.Series.rolling(df['Close'], 5).mean()\n",
    "    df['Avg10'] = pd.Series.rolling(df['Close'], 10).mean()\n",
    "    df['RSI14'] = RSI(df['Close'], 14)\n",
    "    df['RSI7'] = RSI(df['Close'], 7)\n",
    "    df.sort_index(ascending=False, inplace=True)\n",
    "    df['Rise'] = (pd.Series.rolling(df['Close'], 5).max() - df['Close'] > df['Close'] * 0.04) * 1\n",
    "    df.sort_index(ascending=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "def rescale(df):\n",
    "    df.dropna(inplace=True)\n",
    "    values = df.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float')\n",
    "    # drop columns to simplify test\n",
    "    timesteps = 5\n",
    "    features = values.shape[1] - 1\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaled = scaler.fit_transform(values)\n",
    "    scaled = values  # scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, timesteps, 1)\n",
    "    # drop columns we don't want to predict\n",
    "    # reframed.drop(reframed.columns[[10,11,12,13,14,15,16,17,18,19,20]], axis=1, inplace=True)\n",
    "    reframed = pd.DataFrame(reframed)\n",
    "    return reframed\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "@autojit\n",
    "def buildmodel():\n",
    "    model = Sequential()\n",
    "\n",
    "    # this is good .92\n",
    "    model.add(LSTM(20, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(LSTM(20))\n",
    "    model.add(Dense(8, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    '''#this is good .89\n",
    "    model.add(LSTM(20, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(8, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))'''\n",
    "\n",
    "    '''#this is good .88\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(8, input_dim=3, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))'''\n",
    "\n",
    "    # Dense expects a 2-dimensional input (batch_size, features),\n",
    "    # whereas the output of LSTM with return_sequences is 3 dimensional (batch_size, timesteps, features).\n",
    "\n",
    "    # stacked --good acc =0.843\n",
    "    '''model.add(LSTM(4, input_shape=(43, 1)))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    print(model.summary())'''\n",
    "\n",
    "    '''model.add(Bidirectional(LSTM(20, return_sequences=True), input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(TimeDistributed(Dense(1, activation='sigmoid')))'''\n",
    "\n",
    "    # model.compile(loss='mae', optimizer='adam')\n",
    "    # it should be categorical\n",
    "    # model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    history = model.fit(train_X, train_y, epochs=100, batch_size=1, verbose=2)\n",
    "    return model\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# serialize model to JSON\n",
    "def savemodel(model):\n",
    "    model_json = model.to_json()\n",
    "    with open(myModelpath + itemname + \"_model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(myModelpath + itemname + \"_model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "df = read_csv(settingsPath + 'List6.csv', header=None)\n",
    "for index in range (df.shape[0]):\n",
    "    itemname=df.iloc[index,0]\n",
    "    print ('Current item :', itemname)\n",
    "\n",
    "    #itemname = 'CSCO'\n",
    "\n",
    "    dframe = getData(itemname)\n",
    "    dframe = cleanData(dframe)\n",
    "    djiframe = getData('DJI')\n",
    "    djiframe = cleanData(djiframe)\n",
    "    # dframe=dframe.join(djiframe, lsuffix='_left', rsuffix='_right')\n",
    "    dframe = dframe.join(djiframe, rsuffix='_right')\n",
    "\n",
    "    fullFrame = engFeatures(dframe)\n",
    "    reframed = rescale(fullFrame)\n",
    "\n",
    "    train = reframed.values\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], to_categorical(train[:, -1])\n",
    "    train_X = numpy.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "    #print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    # test on entire dataframe\n",
    "    test = reframed.values\n",
    "    test_X, test_y = test[:, :-1], to_categorical(test[:, -1])\n",
    "    test_X = numpy.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
    "\n",
    "    themodel = buildmodel()\n",
    "    #history = themodel.fit(train_X, train_y, epochs=100, batch_size=1, verbose=2)\n",
    "    savemodel(themodel)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
